<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Getting Started with Kaggle &#8211; Riken Shah - Blog</title>
<meta name="description" content="Improving your data science skill in Kaggle">
<meta name="keywords" content="python, data_science, machine_learning">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Getting Started with Kaggle">
<meta name="twitter:description" content="Improving your data science skill in Kaggle">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://0.0.0.0:4000/images/">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Getting Started with Kaggle">
<meta property="og:description" content="Improving your data science skill in Kaggle">
<meta property="og:url" content="http://0.0.0.0:4000/articles/getting-started-with-kaggle/">
<meta property="og:site_name" content="Riken Shah - Blog">





<link rel="canonical" href="http://0.0.0.0:4000/articles/getting-started-with-kaggle/">
<link href="http://0.0.0.0:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Riken Shah - Blog Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://0.0.0.0:4000/assets/css/main.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://0.0.0.0:4000/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://0.0.0.0:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://0.0.0.0:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<!-- MathJax -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link href="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css" rel="stylesheet">

<link rel="shortcut icon" href="http://0.0.0.0:4000/favicon.png">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://0.0.0.0:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://0.0.0.0:4000/images/favicon.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://0.0.0.0:4000/images/favicon.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://0.0.0.0:4000/images/favicon.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://0.0.0.0:4000/images/favicon.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		    <li><a href="http://0.0.0.0:4000/" >Home</a></li>
		  
		    
		    <li><a href="http://0.0.0.0:4000/tags/" >Tags</a></li>
		  
		    
		    <li><a href="http://0.0.0.0:4000/about/" >About</a></li>
		  
		    
		    <li><a href="http://0.0.0.0:4000/blog/" >Posts</a></li>
		  
		    
		    <li><a href="http://0.0.0.0:4000/search/" >Search</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->


<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <ul class="entry-tags">
          <li><a href="http://0.0.0.0:4000/tags/#python" title="Pages tagged python">python</a></li><li><a href="http://0.0.0.0:4000/tags/#data_science" title="Pages tagged data_science">data_science</a></li><li><a href="http://0.0.0.0:4000/tags/#machine_learning" title="Pages tagged machine_learning">machine_learning</a></li>
        </ul>
        
          <h1 class="entry-title">Getting Started with Kaggle</h1>
        
      </header>
      <footer class="entry-meta">
        
        
          <img src="http://0.0.0.0:4000/images/riken.jpg" class="bio-photo" alt="Riken Shah bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Riken Shah</span></span>
        <span class="entry-date date published"><time datetime="2017-01-16T00:00:00-06:00"><i class="fa fa-calendar-o"></i> January 16, 2017</time></span>
        <span class="entry-date date modified"><time datetime="2017-01-16 14:18:57 -0400"><i class="fa fa-pencil"></i> January 16, 2017</time></span>
        <span class="entry-comments"><i class="fa fa-comment-o"></i> <a href="#disqus_thread">Comment</a></span>
        <span class="social-share-twitter">
  <a href="https://twitter.com/intent/tweet?hashtags=python,data_science,machine_learning&amp;text=Getting%20Started%20with%20Kaggle&amp;url=http://0.0.0.0:4000/articles/getting-started-with-kaggle/" title="Share on Twitter" itemprop="Twitter"><i class="fa fa-twitter-square"></i> Tweet</a>
</span>
<span class="social-share-facebook">
  <a href="https://www.facebook.com/sharer/sharer.php?u=http://0.0.0.0:4000/articles/getting-started-with-kaggle/" title="Share on Facebook" itemprop="Facebook"><i class="fa fa-facebook-square"></i> Like</a>
</span>
<span class="social-share-googleplus">
  <a href="https://plus.google.com/share?url=http://0.0.0.0:4000/articles/getting-started-with-kaggle/" title="Share on Google Plus" itemprop="GooglePlus"><i class="fa fa-google-plus-square"></i> +1</a>
</span>
<!-- /.social-share -->
        
      </footer>
      <div class="entry-content">
        <p><a href="https://www.kaggle.com" target="_blank"> Kaggle </a> is a very good platform for improving your Data Science and Machine Learning skills. Following is the heads-up for its practice problem on predicting survival rate among titanic passengers.</p>

<h3 id="some-python-tricks-and-tips-for-data-science">Some python tricks and tips for data science</h3>

<p>Dataset is available <a href="https://www.kaggle.com/c/titanic/data?train.csv" target="_blank"> here </a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load a csv file as a dataframe using Pandas library.
</span><span class="n">titanic</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"titanic_train.csv"</span><span class="p">)</span>

<span class="c1"># Print the first 5 rows of the data frame.
</span><span class="k">print</span><span class="p">(</span><span class="n">titanic</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Get description of the dataframe
</span><span class="k">print</span><span class="p">(</span><span class="n">titanic</span><span class="p">.</span><span class="n">describe</span><span class="p">())</span>

<span class="c1"># To access a column
</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Age"</span><span class="p">]</span>

<span class="c1"># fillna() function fill the column with missing values
# median() is self-explanatory
</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Age"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Age"</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Age"</span><span class="p">].</span><span class="n">median</span><span class="p">())</span>

<span class="c1"># Find all the unique genders -- the column appears to contain only male and female.
</span><span class="k">print</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Sex"</span><span class="p">].</span><span class="n">unique</span><span class="p">())</span>

<span class="c1"># Replace all the occurences of male with the number 0. The objective is to convert all non-numeric values to numeric values
</span><span class="n">titanic</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Sex"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"male"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

</code></pre></div></div>

<h3 id="linear-regression-machine-learning-starts">Linear Regression (Machine Learning Starts)</h3>

<p>To oversimplify, linear Regression is a way of predicting future using past. The simplest form of linear regression is <code class="language-plaintext highlighter-rouge">y = mx + c</code> in which we try to predict y, using input variable x and parameters c and m.</p>

<h4 id="problem-with-linear-regression">Problem with linear regression</h4>
<ul>
  <li>Wonâ€™t work when input variable (past data) and output variable that we are trying to predict (future data) are not linearly related.</li>
  <li>It can not give probabilities, instead just gives an output based on selected threshold.</li>
</ul>

<p>ML Best Practice - Use 3-way folding on your dataset to achieve good results. 
Divide your dataset into three parts, train on first two and test on third, then train on 2nd and 3rd part and test on first, etc.</p>

<h4 id="sk-learn-snippets">Sk-learn snippets</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import the linear regression class
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="c1"># Sklearn also has a helper that makes it easy to do cross validation
</span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="c1"># The columns we'll use to predict the target
</span><span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"SibSp"</span><span class="p">,</span> <span class="s">"Parch"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]</span>

<span class="c1"># Initialize our algorithm class
</span><span class="n">alg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="c1"># Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.
# We set random_state to ensure we get the same splits every time we run this.
</span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">titanic</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">:</span>
    <span class="c1"># The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.
</span>    <span class="n">train_predictors</span> <span class="o">=</span> <span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">,:])</span>
    <span class="c1"># The target we're using to train the algorithm.
</span>    <span class="n">train_target</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">]</span>
    <span class="c1"># Training the algorithm using the predictors and target.
</span>    <span class="n">alg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_predictors</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
    <span class="c1"># We can now make predictions on the test fold
</span>    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">,:])</span>
    <span class="n">predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">)</span>
    
<span class="c1"># Now calculating accuracy
</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># The predictions are in three separate numpy arrays.  Concatenate them into one.  
# We concatenate them on axis 0, as they only have one axis.
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Map predictions to outcomes (only possible outcomes are 1 and 0)
</span><span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="p">.</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span> <span class="o">&lt;=</span><span class="p">.</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">totalPredictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">.</span><span class="n">size</span>

<span class="c1"># How many matches in actual and predicted values
</span><span class="n">totalMatch</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">])</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">totalMatch</span><span class="o">*</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">totalPredictions</span>
</code></pre></div></div>

<h3 id="logistic-regression">Logistic Regression</h3>

<p>To get values between 0 and 1 we use this.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span>

<span class="c1"># Initialize our algorithm
</span><span class="n">alg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)
</span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="p">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span> <span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Take the mean of the scores (because we have one for each fold)
</span><span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">titanic_test</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"titanic_test.csv"</span><span class="p">)</span>

<span class="c1"># Do some cleaning of data
</span><span class="n">titanic_test</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"titanic_test.csv"</span><span class="p">)</span>

<span class="n">titanic_test</span><span class="p">[</span><span class="s">"Age"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_test</span><span class="p">[</span><span class="s">"Age"</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Age"</span><span class="p">].</span><span class="n">median</span><span class="p">())</span>

<span class="n">titanic_test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">titanic_test</span><span class="p">[</span><span class="s">"Sex"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"male"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">titanic_test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">titanic_test</span><span class="p">[</span><span class="s">"Sex"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"female"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">titanic_test</span><span class="p">[</span><span class="s">"Embarked"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_test</span><span class="p">[</span><span class="s">"Embarked"</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="s">"S"</span><span class="p">)</span>
<span class="n">titanic_test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">titanic_test</span><span class="p">[</span><span class="s">"Embarked"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"S"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">titanic_test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">titanic_test</span><span class="p">[</span><span class="s">"Embarked"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"C"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">titanic_test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">titanic_test</span><span class="p">[</span><span class="s">"Embarked"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"Q"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">titanic_test</span><span class="p">[</span><span class="s">"Fare"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic_test</span><span class="p">[</span><span class="s">"Fare"</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="n">titanic_test</span><span class="p">[</span><span class="s">"Fare"</span><span class="p">].</span><span class="n">median</span><span class="p">())</span>

<span class="c1"># Initialize the algorithm class
</span><span class="n">alg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train the algorithm using all the training data
</span><span class="n">alg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">])</span>

<span class="c1"># Make predictions using the test set.
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">titanic_test</span><span class="p">[</span><span class="n">predictors</span><span class="p">])</span>

<span class="c1"># Create a new data frame with only the columns Kaggle wants from the dataset.
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s">"PassengerId"</span><span class="p">:</span> <span class="n">titanic_test</span><span class="p">[</span><span class="s">"PassengerId"</span><span class="p">],</span>
        <span class="s">"Survived"</span><span class="p">:</span> <span class="n">predictions</span>
    <span class="p">})</span>
    
</code></pre></div></div>

<h3 id="random-forests">Random Forests</h3>

<p>Decision trees generally overfit the data and hence we use random forests which are capable of lots.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"SibSp"</span><span class="p">,</span> <span class="s">"Parch"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]</span>

<span class="c1"># Initialize our algorithm with the default paramters
# n_estimators is the number of trees we want to make
# min_samples_split is the minimum number of rows we need to make a split
# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)
</span><span class="n">alg</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="p">.</span><span class="n">KFold</span><span class="p">(</span><span class="n">titanic</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="p">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span> <span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>

<span class="c1"># What an elegant way to get mean!
</span><span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</code></pre></div></div>

<p>Also, we can generate some new features.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating a familysize column
</span><span class="n">titanic</span><span class="p">[</span><span class="s">"FamilySize"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"SibSp"</span><span class="p">]</span> <span class="o">+</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Parch"</span><span class="p">]</span>

<span class="c1"># The .apply method generates a new series
</span><span class="n">titanic</span><span class="p">[</span><span class="s">"NameLength"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Name"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<p>Using regular expressions to extract information from data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span>

<span class="c1"># A function to get the title from a name.
</span><span class="k">def</span> <span class="nf">get_title</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="c1"># Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.
</span>    <span class="n">title_search</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">search</span><span class="p">(</span><span class="s">' ([A-Za-z]+)\.'</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="c1"># If the title exists, extract and return it.
</span>    <span class="k">if</span> <span class="n">title_search</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">title_search</span><span class="p">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="s">""</span>

<span class="c1"># Get all the titles and print how often each one occurs.
</span><span class="n">titles</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Name"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="n">get_title</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pandas</span><span class="p">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">titles</span><span class="p">))</span>

<span class="c1"># Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.
</span><span class="n">title_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Mr"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">"Miss"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s">"Mrs"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">"Master"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s">"Dr"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s">"Rev"</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s">"Major"</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s">"Col"</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s">"Mlle"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s">"Mme"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s">"Don"</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="s">"Lady"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">"Countess"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">"Jonkheer"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">"Sir"</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="s">"Capt"</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s">"Ms"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">title_mapping</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">titles</span><span class="p">[</span><span class="n">titles</span> <span class="o">==</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

<span class="c1"># Verify that we converted everything.
</span><span class="k">print</span><span class="p">(</span><span class="n">pandas</span><span class="p">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">titles</span><span class="p">))</span>

<span class="c1"># Add in the title column.
</span><span class="n">titanic</span><span class="p">[</span><span class="s">"Title"</span><span class="p">]</span> <span class="o">=</span> <span class="n">titles</span>
</code></pre></div></div>

<p>Making a new feature named family id (based on grouping last name), since survival is highly dependent on it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">operator</span>

<span class="c1"># A dictionary mapping family name to id
</span><span class="n">family_id_mapping</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># A function to get the id given a row
</span><span class="k">def</span> <span class="nf">get_family_id</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1"># Find the last name by splitting on a comma
</span>    <span class="n">last_name</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">"Name"</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">","</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Create the family id
</span>    <span class="n">family_id</span> <span class="o">=</span> <span class="s">"{0}{1}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">last_name</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s">"FamilySize"</span><span class="p">])</span>
    <span class="c1"># Look up the id in the mapping
</span>    <span class="k">if</span> <span class="n">family_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">family_id_mapping</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">family_id_mapping</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">current_id</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Get the maximum id from the mapping and add one to it if we don't have an id
</span>            <span class="n">current_id</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">family_id_mapping</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="p">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">family_id_mapping</span><span class="p">[</span><span class="n">family_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_id</span>
    <span class="k">return</span> <span class="n">family_id_mapping</span><span class="p">[</span><span class="n">family_id</span><span class="p">]</span>

<span class="c1"># Get the family ids with the apply method
</span><span class="n">family_ids</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">get_family_id</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># There are a lot of family ids, so we'll compress all of the families under 3 members into one code.
</span><span class="n">family_ids</span><span class="p">[</span><span class="n">titanic</span><span class="p">[</span><span class="s">"FamilySize"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<span class="c1"># Print the count of each unique id.
</span><span class="k">print</span><span class="p">(</span><span class="n">pandas</span><span class="p">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">family_ids</span><span class="p">))</span>

<span class="n">titanic</span><span class="p">[</span><span class="s">"FamilyId"</span><span class="p">]</span> <span class="o">=</span> <span class="n">family_ids</span>
</code></pre></div></div>
<p>Now selecting which features are best. <code class="language-plaintext highlighter-rouge">Sklearn</code> has a function that will help us with feature selection, <code class="language-plaintext highlighter-rouge">SelectKBest</code>. This selects the best features from the data and allows us to specify how many it selects.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>

<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"SibSp"</span><span class="p">,</span> <span class="s">"Parch"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">,</span> <span class="s">"FamilySize"</span><span class="p">,</span> <span class="s">"Title"</span><span class="p">,</span> <span class="s">"FamilyId"</span><span class="p">,</span> <span class="s">"NameLength"</span><span class="p">]</span>

<span class="c1"># Perform feature selection
</span><span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">selector</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">])</span>

<span class="c1"># Get the raw p-values for each feature, and transform from p-values into scores
</span><span class="n">scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">log10</span><span class="p">(</span><span class="n">selector</span><span class="p">.</span><span class="n">pvalues_</span><span class="p">)</span>

<span class="c1"># Plot the scores.  See how "Pclass", "Sex", "Title", and "Fare" are the best?
</span><span class="n">plt</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictors</span><span class="p">)),</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictors</span><span class="p">)),</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s">'vertical'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Pick only the four best features.
</span><span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"Title"</span><span class="p">]</span>

<span class="n">alg</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="p">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span> <span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</code></pre></div></div>

<h3 id="ensembling">Ensembling</h3>

<p>Combining various classifiers to get good results. Note that combining decision trees with random forests wonâ€™t work that well since they are pretty similar. However, combining linear regression with random forests should work well.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># The algorithms we want to ensemble.
# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.
</span><span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">,</span> <span class="s">"FamilySize"</span><span class="p">,</span> <span class="s">"Title"</span><span class="p">,</span> <span class="s">"FamilyId"</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"FamilySize"</span><span class="p">,</span> <span class="s">"Title"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]]</span>
<span class="p">]</span>

<span class="c1"># Initialize the cross validation folds
</span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">titanic</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">:</span>
    <span class="n">train_target</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">]</span>
    <span class="n">full_test_predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Make predictions for each algorithm on each fold
</span>    <span class="k">for</span> <span class="n">alg</span><span class="p">,</span> <span class="n">predictors</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
        <span class="c1"># Fit the algorithm on the training data.
</span>        <span class="n">alg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">,:],</span> <span class="n">train_target</span><span class="p">)</span>
        <span class="c1"># Select and predict on the test fold.  
</span>        <span class="c1"># The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.
</span>        <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">,:].</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">full_test_predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">)</span>
    <span class="c1"># Use a simple ensembling scheme -- just average the predictions to get the final classification.
</span>    <span class="n">test_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">full_test_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">full_test_predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="c1"># Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.
</span>    <span class="n">test_predictions</span><span class="p">[</span><span class="n">test_predictions</span> <span class="o">&lt;=</span> <span class="p">.</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_predictions</span><span class="p">[</span><span class="n">test_predictions</span> <span class="o">&gt;</span> <span class="p">.</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">)</span>

<span class="c1"># Put all the predictions together into one array.
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Compute accuracy by comparing to the training data.
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">]])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div></div>

<p>Submitting a <code class="language-plaintext highlighter-rouge">submission data frame</code> to kaggle.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">,</span> <span class="s">"FamilySize"</span><span class="p">,</span> <span class="s">"Title"</span><span class="p">,</span> <span class="s">"FamilyId"</span><span class="p">]</span>

<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">predictors</span><span class="p">],</span>
    <span class="p">[</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Fare"</span><span class="p">,</span> <span class="s">"FamilySize"</span><span class="p">,</span> <span class="s">"Title"</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="s">"Embarked"</span><span class="p">]]</span>
<span class="p">]</span>

<span class="n">full_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">alg</span><span class="p">,</span> <span class="n">predictors</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
    <span class="c1"># Fit the algorithm using the full training data.
</span>    <span class="n">alg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">titanic</span><span class="p">[</span><span class="s">"Survived"</span><span class="p">])</span>
    <span class="c1"># Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">titanic_test</span><span class="p">[</span><span class="n">predictors</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">full_predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="c1"># The gradient boosting classifier generates better predictions, so we weight it higher.
</span><span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">full_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">full_predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">4</span>

<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1">#This is a submission dataframe
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s">"PassengerId"</span><span class="p">:</span> <span class="n">titanic_test</span><span class="p">[</span><span class="s">"PassengerId"</span><span class="p">],</span>
        <span class="s">"Survived"</span><span class="p">:</span> <span class="n">predictions</span>
    <span class="p">})</span>
    
<span class="c1"># Generating csv file    
</span><span class="n">submission</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">"kaggle.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>Source :</p>

<ol>
  <li><a href="https://www.dataquest.io" target="_blank"> Dataquest </a></li>
</ol>


        
          <div id="disqus_thread"></div><!-- /#disqus_thread -->
          
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'eunotech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="http://0.0.0.0:4000/articles/named-entity-recognition-with-nltk/" class="btn" title="Named Entity Recognition in python using StandfordNER and NLTK">Previous</a>
      
      
        <a href="http://0.0.0.0:4000/articles/data-science-introduction/" class="btn" title="Data Science Introduction">Next</a>
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span>&copy; 2021 Riken Shah. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> - <a href="https://mademistakes.com/work/so-simple-jekyll-theme/" rel="nofollow">So Simple Theme</a>.</span>



<div class="social-icons">
	
	
	
	<a href="https://linkedin.com/in/shahriken#username" title="Riken Shah on LinkedIn" target="_blank"><i class="fa fa-linkedin-square fa-2x"></i></a>
	
	
	
	<a href="https://github.com/rikenshah#username" title="Riken Shah on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	
  
	
  <a href="http://0.0.0.0:4000/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss-square fa-2x"></i></a>
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://0.0.0.0:4000';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://0.0.0.0:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://0.0.0.0:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 'https://www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-89094916-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = 'https://stats.g.doubleclick.net/dc.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



</body>
</html>
